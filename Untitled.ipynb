{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2167c0b-adbe-476d-9d47-37c15459d2a4",
   "metadata": {},
   "source": [
    "**КОСИНУСОМ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50075db-fa5d-4293-ac8a-7fd1c84e0881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def build_matrix(\n",
    "    candidates_path='data/embeddings/candidates_train_text_embeddings.npy',\n",
    "    ocean_path='data/embeddings/OCEAN_embeddings.npy',\n",
    "    vacancies_path='data/embeddings/vacancies_embeddings.npy'\n",
    "):\n",
    "  \n",
    "    candidates = np.load(candidates_path)\n",
    "    print(candidates.shape)\n",
    "    ocean = np.load(ocean_path)\n",
    "    print(ocean.shape)\n",
    "    vacancies = np.load(vacancies_path)\n",
    "    print(vacancies.shape)\n",
    "\n",
    "    C = cosine_distances(candidates, ocean)\n",
    "    P = cosine_distances(vacancies, ocean)\n",
    "\n",
    "    final_matrix = C.dot(P.T) + (1 - C).dot(1 - P.T)\n",
    "    \n",
    "    return final_matrix, C, P\n",
    "\n",
    "def filter_matrix(final_matrix, threshold=0.7):\n",
    "\n",
    "    normalized_matrix = final_matrix.copy()\n",
    "    \n",
    "    row_min = normalized_matrix.min(axis=1).reshape(-1, 1)\n",
    "    row_max = normalized_matrix.max(axis=1).reshape(-1, 1)\n",
    "    \n",
    "    denominator = row_max - row_min\n",
    "    denominator[denominator == 0] = 1\n",
    "    \n",
    "    normalized_matrix = (normalized_matrix - row_min) / denominator\n",
    "    \n",
    "    normalized_matrix[normalized_matrix < threshold] = 0\n",
    "    \n",
    "    return normalized_matrix\n",
    "\n",
    "a, C, P = build_matrix()\n",
    "b = filter_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551dd333-9748-44dc-a505-588c423853bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Используется устройство: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"GPU не доступен. Используется CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ad2b9-d974-4aee-beeb-869453d40ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(embeddings_path):\n",
    "    embeddings = np.load(embeddings_path)\n",
    "    embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "    return embeddings\n",
    "\n",
    "def load_candidates_embeddings(data_folder, max_users=1500):\n",
    "    candidates_train_path = os.path.join(data_folder, 'embeddings', 'candidates_train_text_embeddings.npy')\n",
    "    candidates_val_path = os.path.join(data_folder, 'embeddings', 'candidates_val_text_embeddings.npy')\n",
    "    \n",
    "    candidates_train = load_embeddings(candidates_train_path)\n",
    "    candidates_val = load_embeddings(candidates_val_path)\n",
    "    \n",
    "    # Объединяем обучающие и валидационные эмбеддинги\n",
    "    candidates = torch.cat([candidates_train, candidates_val], dim=0)\n",
    "    \n",
    "    # Ограничиваем количество пользователей до max_users\n",
    "    if candidates.shape[0] > max_users:\n",
    "        candidates = candidates[:max_users]\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "def load_jobs_embeddings(data_folder):\n",
    "    jobs_path = os.path.join(data_folder, 'embeddings', 'vacancies_embeddings.npy')\n",
    "    jobs_embeddings = load_embeddings(jobs_path)\n",
    "    return jobs_embeddings\n",
    "\n",
    "def load_ocean_embeddings(data_folder):\n",
    "    ocean_path = os.path.join(data_folder, 'embeddings', 'OCEAN_embeddings.npy')\n",
    "    ocean_embeddings = load_embeddings(ocean_path)\n",
    "    return ocean_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3ba51-fd79-4103-9567-0632af100d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_video_emb = []\n",
    "for i in os.listdir('data/validation/video_embeddings/'):\n",
    "    emb = np.load(f'data/validation/video_embeddings/{i}')\n",
    "    candidates_video_emb.append(emb[0])\n",
    "candidates_video_emb = np.array(candidates_video_emb)\n",
    "\n",
    "candidates_text_emb = []\n",
    "for i in os.listdir('data/validation/text_embeddings/'):\n",
    "    emb = np.load(f'data/validation/text_embeddings/{i}')\n",
    "    candidates_text_emb.append(emb)\n",
    "candidates_text_emb = np.array(candidates_text_emb)\n",
    "types_emb = np.load('data/embeddings/OCEAN_embeddings.npy')\n",
    "candidates_video_emb_norm = candidates_video_emb / np.linalg.norm(candidates_video_emb, axis=1, keepdims=True)\n",
    "candidates_text_emb_norm = candidates_text_emb / np.linalg.norm(candidates_text_emb, axis=1, keepdims=True)\n",
    "types_emb_norm = types_emb / np.linalg.norm(types_emb, axis=1, keepdims=True)\n",
    "\n",
    "candidates_emb = (candidates_video_emb_norm + candidates_text_emb_norm) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e34308b-5914-4d53-99a3-58bc95344d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к папке с данными\n",
    "data_folder = 'data'\n",
    "\n",
    "# Загрузка эмбеддингов\n",
    "print(\"Загрузка эмбеддингов пользователей...\")\n",
    "candidates = torch.tensor(candidates_emb, dtype=torch.float32)\n",
    "#candidates = load_candidates_embeddings(data_folder)\n",
    "print(f\"Эмбеддинги пользователей загружены: {candidates.shape}\")\n",
    "\n",
    "print(\"Загрузка эмбеддингов OCEAN типов личности...\")\n",
    "ocean = load_ocean_embeddings(data_folder)\n",
    "print(f\"Эмбеддинги OCEAN загружены: {ocean.shape}\")\n",
    "\n",
    "print(\"Загрузка эмбеддингов вакансий...\")\n",
    "jobs = load_jobs_embeddings(data_folder)\n",
    "print(f\"Эмбеддинги вакансий загружены: {jobs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd951ec-d639-4a70-838b-0f4bdb4c9299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def build_graph(candidates, ocean, jobs):\n",
    "    num_candidates = candidates.shape[0]\n",
    "    num_ocean = ocean.shape[0]\n",
    "    num_jobs = jobs.shape[0]\n",
    "    \n",
    "    # Объединяем все эмбеддинги в один\n",
    "    x = torch.cat([candidates, ocean, jobs], dim=0)\n",
    "    \n",
    "    # Создаём рёбра\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    \n",
    "    # Пользователи ↔ OCEAN\n",
    "    for user_idx in range(num_candidates):\n",
    "        for ocean_idx in range(num_ocean):\n",
    "            src = user_idx\n",
    "            dst = num_candidates + ocean_idx\n",
    "            edge_index.append([src, dst])\n",
    "            # Вычисляем косинусное расстояние\n",
    "            distance = 1 - cosine_similarity(candidates[user_idx].unsqueeze(0), ocean[ocean_idx].unsqueeze(0))[0][0]\n",
    "            edge_attr.append(distance)\n",
    "            # Добавляем обратное ребро\n",
    "            edge_index.append([dst, src])\n",
    "            edge_attr.append(distance)\n",
    "    \n",
    "    # Вакансии ↔ OCEAN\n",
    "    for job_idx in range(num_jobs):\n",
    "        for ocean_idx in range(num_ocean):\n",
    "            src = num_candidates + ocean_idx\n",
    "            dst = num_candidates + num_ocean + job_idx\n",
    "            edge_index.append([src, dst])\n",
    "            distance = 1 - cosine_similarity(jobs[job_idx].unsqueeze(0), ocean[ocean_idx].unsqueeze(0))[0][0]\n",
    "            edge_attr.append(distance)\n",
    "            # Добавляем обратное ребро\n",
    "            edge_index.append([dst, src])\n",
    "            edge_attr.append(distance)\n",
    "    \n",
    "    # Пользователи ↔ Вакансии (без весов)\n",
    "    for user_idx in range(num_candidates):\n",
    "        for job_idx in range(num_jobs):\n",
    "            src = user_idx\n",
    "            dst = num_candidates + num_ocean + job_idx\n",
    "            edge_index.append([src, dst])\n",
    "            edge_attr.append(0.0)  # Вес 0 для отсутствующих весов\n",
    "            # Добавляем обратное ребро\n",
    "            edge_index.append([dst, src])\n",
    "            edge_attr.append(0.0)\n",
    "    \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float32)\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc53900-0851-4bf7-b5f7-5eca1b5cb3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Построение графа...\")\n",
    "data = build_graph(candidates, ocean, jobs)\n",
    "print(f\"Граф создан: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f7bf71-947b-4a85-9fb2-1bbaf0bfdfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class GraphSAGEModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3, dropout_prob=0.2):\n",
    "        super(GraphSAGEModel, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels[0]))\n",
    "        self.convs.append(SAGEConv(hidden_channels[0], hidden_channels[1]))\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.convs.append(SAGEConv(hidden_channels[1], hidden_channels[2]))\n",
    "        self.convs.append(SAGEConv(hidden_channels[2], out_channels))\n",
    "\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8cdb15-f75a-4cfc-bb4e-9e26d3656b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "def get_link_labels(edge_index, num_nodes, num_neg_samples=4000000):\n",
    "\n",
    "    #Генерирует положительные и отрицательные примеры для задачи предсказания рёбер.\n",
    "    #Мы будем использовать задачу Link Prediction для предсказания существования рёбер между пользователями и вакансиями.\n",
    "    \n",
    "    pos_edge_index = edge_index\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=pos_edge_index,\n",
    "        num_nodes=num_nodes,\n",
    "        num_neg_samples=num_neg_samples\n",
    "    )\n",
    "    return pos_edge_index, neg_edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c4e412-5747-48c3-a9c0-a9a343dd7822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class LinkPredictionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, num_neg_samples=4000000):\n",
    "        self.data = data\n",
    "        self.num_neg_samples = num_neg_samples\n",
    "        self.pos_edge_index, self.neg_edge_index = get_link_labels(\n",
    "            data.edge_index,\n",
    "            num_nodes=data.num_nodes,\n",
    "            num_neg_samples=num_neg_samples\n",
    "        )\n",
    "        # Перемещаем рёбра на GPU\n",
    "        self.pos_edge_index = self.pos_edge_index.to(device)\n",
    "        self.neg_edge_index = self.neg_edge_index.to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1  # В данном случае весь граф обучается за один раз\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.pos_edge_index, self.neg_edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede45fb0-75bc-4155-80d9-cde4fb6f3be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, data, pos_edge_index, neg_edge_index):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out = model(data.x, data.edge_index, data.edge_attr)\n",
    "\n",
    "    pos_pred = (out[pos_edge_index[0]] * out[pos_edge_index[1]]).sum(dim=1)\n",
    "\n",
    "    neg_pred = (out[neg_edge_index[0]] * out[neg_edge_index[1]]).sum(dim=1)\n",
    "\n",
    "    \n",
    "    # Логистическая регрессия\n",
    "    pos_loss = F.binary_cross_entropy_with_logits(pos_pred, torch.ones(pos_pred.size(0), device=device))\n",
    "    neg_loss = F.binary_cross_entropy_with_logits(neg_pred, torch.zeros(neg_pred.size(0), device=device))\n",
    "\n",
    "    \n",
    "    loss = pos_loss + neg_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
    "\n",
    "def test(model, data, pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index, data.edge_attr)\n",
    "        \n",
    "        # Предсказания для положительных и отрицательных рёбер\n",
    "        pos_pred = (out[pos_edge_index[0]] * out[pos_edge_index[1]]).sum(dim=1)\n",
    "        neg_pred = (out[neg_edge_index[0]] * out[neg_edge_index[1]]).sum(dim=1)\n",
    "        \n",
    "        # Объединяем предсказания и метки\n",
    "        preds = torch.cat([pos_pred, neg_pred], dim=0)\n",
    "        labels = torch.cat([torch.ones(pos_pred.size(0), device=device), torch.zeros(neg_pred.size(0), device=device)], dim=0)\n",
    "        \n",
    "        # Применяем сигмоиду для перевода предсказаний в диапазон [0, 1]\n",
    "        preds = torch.sigmoid(preds)\n",
    "        preds = preds.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        \n",
    "        # Вычисление AUC\n",
    "        auc = roc_auc_score(labels, preds)\n",
    "        \n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e3f96-978e-44b2-91b7-89e8ecf3dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def main_training_loop():\n",
    "    # Создание графа\n",
    "    #print(\"Построение графа...\")\n",
    "    #data = build_graph(candidates, ocean, jobs)\n",
    "    #print(f\"Граф создан: {data}\")\n",
    "    \n",
    "    num_nodes = data.num_nodes\n",
    "    \n",
    "    # Создание датасета и загрузчика данных\n",
    "    dataset = LinkPredictionDataset(data, num_neg_samples=4000000)  # Увеличиваем отрицательные примеры\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    # Определение модели\n",
    "    in_channels = data.x.shape[1]\n",
    "    hidden_channels = [384, 256, 128]  # Указанные размеры для скрытых слоев\n",
    "    out_channels = 64  # Размерность выхода\n",
    "    model = GraphSAGEModel(in_channels, hidden_channels, out_channels, dropout_prob=0.2).to(device)\n",
    "    \n",
    "    # Перевод данных на GPU\n",
    "    data.x = data.x.to(device)\n",
    "    data.edge_attr = data.edge_attr.to(device)\n",
    "    data.edge_index = data.edge_index.to(device)\n",
    "\n",
    "    # Оптимизатор и планировщик\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)  # Уменьшаем lr каждые 20 эпох\n",
    "\n",
    "    # Очистка памяти\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Обучение\n",
    "    epochs = 200\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for pos_edge, neg_edge in dataloader:\n",
    "            pos_edge = pos_edge[0].to(device)\n",
    "            neg_edge = neg_edge[0].to(device)\n",
    "            loss = train(model, optimizer, data, pos_edge, neg_edge)\n",
    "        \n",
    "        # Обновление планировщика\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Оценка модели каждые 10 эпох\n",
    "        if epoch % 10 == 0:\n",
    "            auc = test(model, data, pos_edge, neg_edge)\n",
    "            print(f'Epoch {epoch}, Loss: {loss:.4f}, AUC: {auc:.4f}')\n",
    "    \n",
    "    # Сохранение модели\n",
    "    model_save_path = 'graphsage_model1.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Модель сохранена по пути: {model_save_path}\")\n",
    "    \n",
    "    return model, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8edfe2-ca73-4dfc-bef3-393f9583dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"data.x device: {data.x.device}\")\n",
    "print(f\"data.edge_attr device: {data.edge_attr.device}\")\n",
    "print(f\"data.edge_index device: {data.edge_index.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ffb368-f07b-4026-b472-5059e2a1b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, data = main_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c59d043-2093-45c9-9989-5ea55a029d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "def generate_weight_matrix(model, data, num_candidates, num_jobs, top_k=None):\n",
    "    \"\"\"\n",
    "    Генерирует матрицу весов между пользователями и вакансиями.\n",
    "    \n",
    "    Параметры:\n",
    "    - model (torch.nn.Module): Обученная модель GraphSAGE.\n",
    "    - data (torch_geometric.data.Data): Объект данных графа.\n",
    "    - num_candidates (int): Количество пользователей.\n",
    "    - num_jobs (int): Количество вакансий.\n",
    "    - top_k (int или None): Если задано, возвращает только топ-k вакансий для каждого пользователя.\n",
    "    \n",
    "    Возвращает:\n",
    "    - weight_matrix (np.ndarray): Матрица весов размерности (num_candidates, num_jobs).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index, data.edge_attr)\n",
    "    \n",
    "    # Извлечение эмбеддингов пользователей и вакансий\n",
    "    user_embeddings = out[:num_candidates].cpu().numpy()\n",
    "    job_embeddings = out[num_candidates + 5:num_candidates + 5 + num_jobs].cpu().numpy()  # 5 OCEAN типов\n",
    "    \n",
    "    # Нормализация эмбеддингов для вычисления косинусного сходства\n",
    "    user_norm = np.linalg.norm(user_embeddings, axis=1, keepdims=True)\n",
    "    job_norm = np.linalg.norm(job_embeddings, axis=1, keepdims=True)\n",
    "    user_embeddings_norm = user_embeddings / (user_norm + 1e-10)\n",
    "    job_embeddings_norm = job_embeddings / (job_norm + 1e-10)\n",
    "    \n",
    "    # Вычисление матрицы косинусного сходства\n",
    "    weight_matrix = np.dot(user_embeddings_norm, job_embeddings_norm.T)\n",
    "    \n",
    "    if top_k is not None:\n",
    "        # Ограничение до топ_k вакансий для каждого пользователя\n",
    "        indices = np.argsort(weight_matrix, axis=1)[:, -top_k:]\n",
    "        sorted_indices = np.argsort(indices, axis=1)\n",
    "        top_weights = np.take_along_axis(weight_matrix, indices, axis=1)\n",
    "        weight_matrix_top_k = np.zeros_like(weight_matrix)\n",
    "        for i in range(num_candidates):\n",
    "            weight_matrix_top_k[i, indices[i]] = weight_matrix[i, indices[i]]\n",
    "        return weight_matrix_top_k\n",
    "    else:\n",
    "        return weight_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb85b52-dc07-48df-af44-d9e272925bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d32f6365-cb9a-486f-b270-31735f35b2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка эмбеддингов пользователей...\n",
      "Эмбеддинги пользователей загружены: torch.Size([2000, 384])\n",
      "Загрузка эмбеддингов OCEAN типов личности...\n",
      "Эмбеддинги OCEAN загружены: torch.Size([5, 384])\n",
      "Загрузка эмбеддингов вакансий...\n",
      "Эмбеддинги вакансий загружены: torch.Size([2277, 384])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def load_embeddings(embeddings_path):\n",
    "    embeddings = np.load(embeddings_path)\n",
    "    embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "    return embeddings\n",
    "\n",
    "def load_candidates_embeddings(data_folder, max_users=1500):\n",
    "    candidates_train_path = os.path.join(data_folder, 'embeddings', 'candidates_train_text_embeddings.npy')\n",
    "    candidates_val_path = os.path.join(data_folder, 'embeddings', 'candidates_val_text_embeddings.npy')\n",
    "    \n",
    "    candidates_train = load_embeddings(candidates_train_path)\n",
    "    candidates_val = load_embeddings(candidates_val_path)\n",
    "    \n",
    "    # Объединяем обучающие и валидационные эмбеддинги\n",
    "    candidates = torch.cat([candidates_train, candidates_val], dim=0)\n",
    "    \n",
    "    # Ограничиваем количество пользователей до max_users\n",
    "    if candidates.shape[0] > max_users:\n",
    "        candidates = candidates[:max_users]\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "def load_jobs_embeddings(data_folder):\n",
    "    jobs_path = os.path.join(data_folder, 'embeddings', 'vacancies_embeddings.npy')\n",
    "    jobs_embeddings = load_embeddings(jobs_path)\n",
    "    return jobs_embeddings\n",
    "\n",
    "def load_ocean_embeddings(data_folder):\n",
    "    ocean_path = os.path.join(data_folder, 'embeddings', 'OCEAN_embeddings.npy')\n",
    "    ocean_embeddings = load_embeddings(ocean_path)\n",
    "    return ocean_embeddings\n",
    "    \n",
    "candidates_video_emb = []\n",
    "for i in os.listdir('data/validation/video_embeddings/'):\n",
    "    emb = np.load(f'data/validation/video_embeddings/{i}')\n",
    "    candidates_video_emb.append(emb[0])\n",
    "candidates_video_emb = np.array(candidates_video_emb)\n",
    "\n",
    "candidates_text_emb = []\n",
    "for i in os.listdir('data/validation/text_embeddings/'):\n",
    "    emb = np.load(f'data/validation/text_embeddings/{i}')\n",
    "    candidates_text_emb.append(emb)\n",
    "candidates_text_emb = np.array(candidates_text_emb)\n",
    "types_emb = np.load('data/embeddings/OCEAN_embeddings.npy')\n",
    "candidates_video_emb_norm = candidates_video_emb / np.linalg.norm(candidates_video_emb, axis=1, keepdims=True)\n",
    "candidates_text_emb_norm = candidates_text_emb / np.linalg.norm(candidates_text_emb, axis=1, keepdims=True)\n",
    "types_emb_norm = types_emb / np.linalg.norm(types_emb, axis=1, keepdims=True)\n",
    "\n",
    "candidates_emb = (candidates_video_emb_norm + candidates_text_emb_norm) / 2\n",
    "\n",
    "\n",
    "# Путь к папке с данными\n",
    "data_folder = 'data'\n",
    "\n",
    "# Загрузка эмбеддингов\n",
    "print(\"Загрузка эмбеддингов пользователей...\")\n",
    "user_embeddings = torch.tensor(candidates_emb, dtype=torch.float32)\n",
    "#candidates = load_candidates_embeddings(data_folder)\n",
    "print(f\"Эмбеддинги пользователей загружены: {user_embeddings.shape}\")\n",
    "\n",
    "print(\"Загрузка эмбеддингов OCEAN типов личности...\")\n",
    "ocean_embeddings = load_ocean_embeddings(data_folder)\n",
    "print(f\"Эмбеддинги OCEAN загружены: {ocean_embeddings.shape}\")\n",
    "\n",
    "print(\"Загрузка эмбеддингов вакансий...\")\n",
    "vacancy_embeddings = load_jobs_embeddings(data_folder)\n",
    "print(f\"Эмбеддинги вакансий загружены: {vacancy_embeddings.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07706290-4c3f-4a08-8a2f-6a24b6e1f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "num_users = user_embeddings.shape[0]\n",
    "num_ocean = ocean_embeddings.shape[0]\n",
    "num_vacancies = vacancy_embeddings.shape[0]\n",
    "\n",
    "# Создаем список всех вершин\n",
    "num_nodes = num_users + num_ocean + num_vacancies\n",
    "\n",
    "# Создаем ребра\n",
    "edge_index = []\n",
    "edge_weight = []\n",
    "\n",
    "# Пользователь ↔ OCEAN\n",
    "user_ocean_sim = cosine_similarity(user_embeddings, ocean_embeddings)\n",
    "for user in range(num_users):\n",
    "    for ocean in range(num_ocean):\n",
    "        edge_index.append([user, num_users + ocean])\n",
    "        edge_weight.append(user_ocean_sim[user, ocean])\n",
    "\n",
    "# Вакансия ↔ OCEAN\n",
    "vacancy_ocean_sim = cosine_similarity(vacancy_embeddings, ocean_embeddings)  # (2277, 5)\n",
    "for vacancy in range(num_vacancies):\n",
    "    for ocean in range(num_ocean):\n",
    "        edge_index.append([num_users + ocean, num_users + num_ocean + vacancy])\n",
    "        edge_weight.append(1 - vacancy_ocean_sim[vacancy, ocean])  # Косинусное расстояние\n",
    "\n",
    "# Пользователь ↔ Вакансия (без весов или с начальными весами)\n",
    "# Для примера, создадим полносвязные связи (можно использовать более эффективный подход)\n",
    "# Но из-за большого количества связей это может быть неэффективно\n",
    "# Альтернативно, можно использовать выборку или другие методы для создания связей\n",
    "\n",
    "# Здесь для примера ограничимся связями только через OCEAN\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "edge_weight = torch.tensor(edge_weight, dtype=torch.float)\n",
    "\n",
    "# Создание графа\n",
    "data = Data(x=torch.tensor(np.vstack([user_embeddings, ocean_embeddings, vacancy_embeddings]), dtype=torch.float),\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d71e43b9-c76c-4229-9030-da69cb1d4a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGEModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGEModel, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels[0])\n",
    "        self.conv2 = SAGEConv(hidden_channels[0], hidden_channels[1])\n",
    "        self.conv3 = SAGEConv(hidden_channels[1], out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GraphSAGEModel(in_channels=384, hidden_channels=[256, 128], out_channels=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5993b8e3-1d84-4641-8430-f9501a0fbc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGEModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGEModel, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GraphSAGEModel(in_channels=384, hidden_channels=128, out_channels=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cb4fe5c-bbd5-4f4c-9679-bae9d2d6486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7390886545181274\n",
      "Epoch 10, Loss: 0.005078461021184921\n",
      "Epoch 20, Loss: 0.005078461021184921\n",
      "Epoch 30, Loss: 0.005078461021184921\n",
      "Epoch 40, Loss: 0.005078461021184921\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(cosine_similarity(user_embeddings, vacancy_embeddings), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(similarity, target)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#scheduler.step()\u001b[39;00m\n",
      "File \u001b[0;32m~/HireSnap/venv/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HireSnap/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Получение эмбеддингов после прохождения через GraphSAGE\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index, edge_weight=data.edge_attr)\n",
    "    \n",
    "    # Извлекаем эмбеддинги пользователей и вакансий\n",
    "    user_out = out[:num_users]\n",
    "    vacancy_out = out[num_users + num_ocean:]\n",
    "    \n",
    "    # Вычисляем косинусное сходство между пользователями и вакансиями\n",
    "    similarity = torch.mm(user_out, vacancy_out.t())  # (1000, 2277)\n",
    "    similarity = similarity / (user_out.norm(dim=1).unsqueeze(1) * vacancy_out.norm(dim=1).unsqueeze(0))\n",
    "    similarity = similarity.clamp(0, 1)\n",
    "    \n",
    "    # Поскольку у нас нет явных меток, можно использовать косинусное сходство эмбеддингов как целевую\n",
    "    target = torch.tensor(cosine_similarity(user_embeddings, vacancy_embeddings), dtype=torch.float)\n",
    "    \n",
    "    loss = criterion(similarity, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #scheduler.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b091470-ff69-4eea-9492-cef28f0a1b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(data.x, data.edge_index, edge_weight=data.edge_attr)\n",
    "    user_out = out[:num_users]\n",
    "    vacancy_out = out[num_users + num_ocean:]\n",
    "    \n",
    "    # Нормализация эмбеддингов\n",
    "    user_norm = user_out / user_out.norm(dim=1, keepdim=True)\n",
    "    vacancy_norm = vacancy_out / vacancy_out.norm(dim=1, keepdim=True)\n",
    "    \n",
    "    # Косинусное сходство\n",
    "    similarity_matrix = torch.mm(user_norm, vacancy_norm.t())  # (1000, 2277)\n",
    "    similarity_matrix = similarity_matrix.clamp(0, 1)\n",
    "    \n",
    "    # Преобразование в numpy\n",
    "    similarity_matrix = similarity_matrix.cpu().numpy()\n",
    "\n",
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa7f696-0076-4646-ad19-fedfb43f6c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_matrix(final_matrix, threshold=0.5):\n",
    "\n",
    "    normalized_matrix = final_matrix.copy()\n",
    "    \n",
    "    row_min = normalized_matrix.min(axis=1).reshape(-1, 1)\n",
    "    row_max = normalized_matrix.max(axis=1).reshape(-1, 1)\n",
    "    \n",
    "    denominator = row_max - row_min\n",
    "    denominator[denominator == 0] = 1\n",
    "    \n",
    "    normalized_matrix = (normalized_matrix - row_min) / denominator\n",
    "    \n",
    "    normalized_matrix[normalized_matrix < threshold] = 0\n",
    "    \n",
    "    return normalized_matrix\n",
    "a = filter_matrix(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94901113-da9e-4308-ab87-7327652c2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_cosine_distances_first_n_candidates(matrix, n=10):\n",
    "\n",
    "    n = min(n, matrix.shape[0])  # Убедимся, что n не превышает количество кандидатов\n",
    "    num_vacancies = matrix.shape[1]\n",
    "    \n",
    "    # Определяем сетку подграфиков (например, 2 строки по 5 столбцов для 10 графиков)\n",
    "    rows = 5\n",
    "    cols = 2\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(25, 20))\n",
    "    axes = axes.flatten()  # Преобразуем массив осей в одномерный для удобства итерации\n",
    "    \n",
    "    for i in range(n):\n",
    "        ax = axes[i]\n",
    "        candidate_distances = matrix[i, :]\n",
    "        vacancies = np.arange(1, num_vacancies + 1)  # Индексы вакансий\n",
    "        \n",
    "        ax.bar(vacancies, candidate_distances, color='skyblue')\n",
    "        ax.set_title(f'Кандидат {i+1}', fontsize=14)\n",
    "        ax.set_xlabel('Вакансии', fontsize=12)\n",
    "        ax.set_ylabel('Косинусное расстояние', fontsize=12)\n",
    "        ax.set_ylim(0, 1)  # Поскольку матрица нормализована\n",
    "        ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)  # Скрываем метки по оси X для чистоты графика\n",
    "    \n",
    "    # Если количество графиков меньше 10, удаляем лишние подграфики\n",
    "    for j in range(n, rows * cols):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_cosine_distances_first_n_candidates(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "579bb02a-f38a-49f4-b4b8-ee5a01f80df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка эмбеддингов пользователей...\n",
      "Эмбеддинги пользователей загружены: torch.Size([2000, 384])\n",
      "Загрузка эмбеддингов OCEAN типов личности...\n",
      "Эмбеддинги OCEAN загружены: torch.Size([5, 384])\n",
      "Загрузка эмбеддингов вакансий...\n",
      "Эмбеддинги вакансий загружены: torch.Size([2277, 384])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def load_embeddings(embeddings_path):\n",
    "    embeddings = np.load(embeddings_path)\n",
    "    embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "    return embeddings\n",
    "\n",
    "def load_candidates_embeddings(data_folder, max_users=1500):\n",
    "    candidates_train_path = os.path.join(data_folder, 'embeddings', 'candidates_train_text_embeddings.npy')\n",
    "    candidates_val_path = os.path.join(data_folder, 'embeddings', 'candidates_val_text_embeddings.npy')\n",
    "    \n",
    "    candidates_train = load_embeddings(candidates_train_path)\n",
    "    candidates_val = load_embeddings(candidates_val_path)\n",
    "    \n",
    "    # Объединяем обучающие и валидационные эмбеддинги\n",
    "    candidates = torch.cat([candidates_train, candidates_val], dim=0)\n",
    "    \n",
    "    # Ограничиваем количество пользователей до max_users\n",
    "    if candidates.shape[0] > max_users:\n",
    "        candidates = candidates[:max_users]\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "def load_jobs_embeddings(data_folder):\n",
    "    jobs_path = os.path.join(data_folder, 'embeddings', 'vacancies_embeddings.npy')\n",
    "    jobs_embeddings = load_embeddings(jobs_path)\n",
    "    return jobs_embeddings\n",
    "\n",
    "def load_ocean_embeddings(data_folder):\n",
    "    ocean_path = os.path.join(data_folder, 'embeddings', 'OCEAN_embeddings.npy')\n",
    "    ocean_embeddings = load_embeddings(ocean_path)\n",
    "    return ocean_embeddings\n",
    "    \n",
    "candidates_video_emb = []\n",
    "for i in os.listdir('data/validation/video_embeddings/'):\n",
    "    emb = np.load(f'data/validation/video_embeddings/{i}')\n",
    "    candidates_video_emb.append(emb[0])\n",
    "candidates_video_emb = np.array(candidates_video_emb)\n",
    "\n",
    "candidates_text_emb = []\n",
    "for i in os.listdir('data/validation/text_embeddings/'):\n",
    "    emb = np.load(f'data/validation/text_embeddings/{i}')\n",
    "    candidates_text_emb.append(emb)\n",
    "candidates_text_emb = np.array(candidates_text_emb)\n",
    "types_emb = np.load('data/embeddings/OCEAN_embeddings.npy')\n",
    "candidates_video_emb_norm = candidates_video_emb / np.linalg.norm(candidates_video_emb, axis=1, keepdims=True)\n",
    "candidates_text_emb_norm = candidates_text_emb / np.linalg.norm(candidates_text_emb, axis=1, keepdims=True)\n",
    "types_emb_norm = types_emb / np.linalg.norm(types_emb, axis=1, keepdims=True)\n",
    "\n",
    "candidates_emb = (candidates_video_emb_norm + candidates_text_emb_norm) / 2\n",
    "\n",
    "\n",
    "# Путь к папке с данными\n",
    "data_folder = 'data'\n",
    "\n",
    "# Загрузка эмбеддингов\n",
    "print(\"Загрузка эмбеддингов пользователей...\")\n",
    "user_embeddings  = torch.tensor(candidates_emb, dtype=torch.float32)\n",
    "#candidates = load_candidates_embeddings(data_folder)\n",
    "print(f\"Эмбеддинги пользователей загружены: {user_embeddings.shape}\")\n",
    "\n",
    "print(\"Загрузка эмбеддингов OCEAN типов личности...\")\n",
    "ocean_embeddings  = load_ocean_embeddings(data_folder)\n",
    "print(f\"Эмбеддинги OCEAN загружены: {ocean_embeddings.shape}\")\n",
    "\n",
    "print(\"Загрузка эмбеддингов вакансий...\")\n",
    "vacancy_embeddings  = load_jobs_embeddings(data_folder)\n",
    "print(f\"Эмбеддинги вакансий загружены: {vacancy_embeddings.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48658ea3-7d0d-4ee5-986c-73ad04e0d29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка эмбеддингов пользователей...\n",
      "Эмбеддинги пользователей загружены: torch.Size([2000, 384])\n",
      "Загрузка эмбеддингов OCEAN типов личности...\n",
      "Эмбеддинги OCEAN загружены: torch.Size([5, 384])\n",
      "Загрузка эмбеддингов вакансий...\n",
      "Эмбеддинги вакансий загружены: torch.Size([2277, 384])\n",
      "Train Data:\n",
      "Data(x=[4282, 384], edge_index=[2, 14000], edge_attr=[14000], pos_edge_label=[7000], pos_edge_label_index=[2, 7000], neg_edge_label=[7000], neg_edge_label_index=[2, 7000])\n",
      "\n",
      "Validation Data:\n",
      "Data(x=[4282, 384], edge_index=[2, 14000], edge_attr=[14000], pos_edge_label=[1500], pos_edge_label_index=[2, 1500], neg_edge_label=[1500], neg_edge_label_index=[2, 1500])\n",
      "\n",
      "Test Data:\n",
      "Data(x=[4282, 384], edge_index=[2, 17000], edge_attr=[17000], pos_edge_label=[1500], pos_edge_label_index=[2, 1500], neg_edge_label=[1500], neg_edge_label_index=[2, 1500])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def load_embeddings(embeddings_path):\n",
    "    embeddings = np.load(embeddings_path)\n",
    "    embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "    return embeddings\n",
    "\n",
    "def load_candidates_embeddings(data_folder, max_users=1500):\n",
    "    candidates_train_path = os.path.join(data_folder, 'embeddings', 'candidates_train_text_embeddings.npy')\n",
    "    candidates_val_path = os.path.join(data_folder, 'embeddings', 'candidates_val_text_embeddings.npy')\n",
    "    \n",
    "    candidates_train = load_embeddings(candidates_train_path)\n",
    "    candidates_val = load_embeddings(candidates_val_path)\n",
    "    \n",
    "    # Объединяем обучающие и валидационные эмбеддинги\n",
    "    candidates = torch.cat([candidates_train, candidates_val], dim=0)\n",
    "    \n",
    "    # Ограничиваем количество пользователей до max_users\n",
    "    if candidates.shape[0] > max_users:\n",
    "        candidates = candidates[:max_users]\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "def load_jobs_embeddings(data_folder):\n",
    "    jobs_path = os.path.join(data_folder, 'embeddings', 'vacancies_embeddings.npy')\n",
    "    jobs_embeddings = load_embeddings(jobs_path)\n",
    "    return jobs_embeddings\n",
    "\n",
    "def load_ocean_embeddings(data_folder):\n",
    "    ocean_path = os.path.join(data_folder, 'embeddings', 'OCEAN_embeddings.npy')\n",
    "    ocean_embeddings = load_embeddings(ocean_path)\n",
    "    return ocean_embeddings\n",
    "    \n",
    "candidates_video_emb = []\n",
    "for i in os.listdir('data/validation/video_embeddings/'):\n",
    "    emb = np.load(f'data/validation/video_embeddings/{i}')\n",
    "    candidates_video_emb.append(emb[0])\n",
    "candidates_video_emb = np.array(candidates_video_emb)\n",
    "\n",
    "candidates_text_emb = []\n",
    "for i in os.listdir('data/validation/text_embeddings/'):\n",
    "    emb = np.load(f'data/validation/text_embeddings/{i}')\n",
    "    candidates_text_emb.append(emb)\n",
    "candidates_text_emb = np.array(candidates_text_emb)\n",
    "types_emb = np.load('data/embeddings/OCEAN_embeddings.npy')\n",
    "candidates_video_emb_norm = candidates_video_emb / np.linalg.norm(candidates_video_emb, axis=1, keepdims=True)\n",
    "candidates_text_emb_norm = candidates_text_emb / np.linalg.norm(candidates_text_emb, axis=1, keepdims=True)\n",
    "types_emb_norm = types_emb / np.linalg.norm(types_emb, axis=1, keepdims=True)\n",
    "\n",
    "candidates_emb = (candidates_video_emb_norm + candidates_text_emb_norm) / 2\n",
    "\n",
    "\n",
    "# Путь к папке с данными\n",
    "data_folder = 'data'\n",
    "\n",
    "# Загрузка эмбеддингов\n",
    "print(\"Загрузка эмбеддингов пользователей...\")\n",
    "user_embeddings = torch.tensor(candidates_emb, dtype=torch.float32)\n",
    "#candidates = load_candidates_embeddings(data_folder)\n",
    "print(f\"Эмбеддинги пользователей загружены: {user_embeddings.shape}\")\n",
    "\n",
    "print(\"Загрузка эмбеддингов OCEAN типов личности...\")\n",
    "ocean_embeddings = load_ocean_embeddings(data_folder)\n",
    "print(f\"Эмбеддинги OCEAN загружены: {ocean_embeddings.shape}\")\n",
    "\n",
    "print(\"Загрузка эмбеддингов вакансий...\")\n",
    "vacancy_embeddings = load_jobs_embeddings(data_folder)\n",
    "print(f\"Эмбеддинги вакансий загружены: {vacancy_embeddings.shape}\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import normalize\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def safe_normalize(tensor, dim=1, eps=1e-10):\n",
    "    return tensor / (tensor.norm(p=2, dim=dim, keepdim=True) + eps)\n",
    "# Нормализация эмбеддингов для вычисления косинусного сходства\n",
    "user_embeddings = safe_normalize(user_embeddings)\n",
    "ocean_embeddings = safe_normalize(ocean_embeddings)\n",
    "vacancy_embeddings = safe_normalize(vacancy_embeddings)\n",
    "\n",
    "# Создание индексов вершин\n",
    "num_users = user_embeddings.shape[0]\n",
    "num_ocean = ocean_embeddings.shape[0]\n",
    "num_vacancies = vacancy_embeddings.shape[0]\n",
    "\n",
    "total_nodes = num_users + num_ocean + num_vacancies\n",
    "\n",
    "# Индексация:\n",
    "# Пользователи: 0 - 1999\n",
    "# OCEAN: 2000 - 2004\n",
    "# Вакансии: 2005 - 4281\n",
    "\n",
    "# Создание списка ребер\n",
    "edge_index = []\n",
    "edge_weights = []\n",
    "\n",
    "# Связи между пользователями и OCEAN\n",
    "\n",
    "for user_idx in range(num_users):\n",
    "    for ocean_idx in range(num_ocean):\n",
    "        global_user_idx = user_idx\n",
    "        global_ocean_idx = num_users + ocean_idx\n",
    "        edge_index.append([global_user_idx, global_ocean_idx])\n",
    "        # Косинусное сходство нормализовано до [0,1]\n",
    "        similarity = float((torch.dot(user_embeddings[user_idx], ocean_embeddings[ocean_idx]) + 1) / 2)\n",
    "        edge_weights.append(similarity)\n",
    "\n",
    "# Связи между вакансиями и OCEAN\n",
    "for vacancy_idx in range(num_vacancies):\n",
    "    for ocean_idx in range(num_ocean):\n",
    "        global_vacancy_idx = num_users + num_ocean + vacancy_idx\n",
    "        global_ocean_idx = num_users + ocean_idx\n",
    "        edge_index.append([global_vacancy_idx, global_ocean_idx])\n",
    "        similarity = float((torch.dot(vacancy_embeddings[vacancy_idx], ocean_embeddings[ocean_idx]) + 1) / 2)\n",
    "        edge_weights.append(similarity)\n",
    "\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "edge_weight = torch.tensor(edge_weights, dtype=torch.float)\n",
    "\n",
    "# Создание признаков узлов\n",
    "x = torch.tensor(\n",
    "    np.vstack([user_embeddings, ocean_embeddings, vacancy_embeddings]),\n",
    "    dtype=torch.float\n",
    ")\n",
    "\n",
    "# Создание графа\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_weight)\n",
    "\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "# Инициализация трансформера\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.15,      # 5% ребер для валидации\n",
    "    num_test=0.15,      # 10% ребер для тестирования\n",
    "    is_undirected=True, # Граф неориентированный\n",
    "    add_negative_train_samples=True, # Не добавляем отрицательные примеры в обучающую выборку\n",
    "    split_labels=True\n",
    ")\n",
    "\n",
    "# Применение трансформации\n",
    "train_data, val_data, test_data = transform(data)\n",
    "print(\"Train Data:\")\n",
    "print(train_data)\n",
    "print(\"\\nValidation Data:\")\n",
    "print(val_data)\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fa4ffdf-9326-45aa-9af9-4dbac7053a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge weights are clean\n"
     ]
    }
   ],
   "source": [
    "def check_edge_weights(edge_weight):\n",
    "    if torch.isnan(edge_weight).any():\n",
    "        print(\"NaN detected in edge weights\")\n",
    "    elif torch.isinf(edge_weight).any():\n",
    "        print(\"Infinite value detected in edge weights\")\n",
    "    else:\n",
    "        print(\"Edge weights are clean\")\n",
    "\n",
    "check_edge_weights(edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53cde04d-d655-4bc2-a55a-f28596ea6bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.3739, Val AUC: 0.9994\n",
      "Epoch: 20, Loss: 0.3585, Val AUC: 0.9994\n",
      "Epoch: 30, Loss: 0.3547, Val AUC: 0.9995\n",
      "Epoch: 40, Loss: 0.3556, Val AUC: 0.9995\n",
      "Epoch: 50, Loss: 0.3520, Val AUC: 0.9996\n",
      "Epoch: 60, Loss: 0.3501, Val AUC: 0.9996\n",
      "Epoch: 70, Loss: 0.3517, Val AUC: 0.9997\n",
      "Epoch: 80, Loss: 0.3527, Val AUC: 0.9997\n",
      "Epoch: 90, Loss: 0.3495, Val AUC: 0.9997\n",
      "Epoch: 100, Loss: 0.3505, Val AUC: 0.9998\n",
      "Epoch: 110, Loss: 0.3542, Val AUC: 0.9998\n",
      "Epoch: 120, Loss: 0.3493, Val AUC: 0.9998\n",
      "Epoch: 130, Loss: 0.3500, Val AUC: 0.9998\n",
      "Epoch: 140, Loss: 0.3490, Val AUC: 0.9998\n",
      "Epoch: 150, Loss: 0.3506, Val AUC: 0.9998\n",
      "Epoch: 160, Loss: 0.3515, Val AUC: 0.9998\n",
      "Epoch: 170, Loss: 0.3497, Val AUC: 0.9998\n",
      "Epoch: 180, Loss: 0.3743, Val AUC: 0.9998\n",
      "Epoch: 190, Loss: 0.3498, Val AUC: 0.9998\n",
      "Epoch: 200, Loss: 0.3506, Val AUC: 0.9998\n",
      "Epoch: 210, Loss: 0.3485, Val AUC: 0.9999\n",
      "Epoch: 220, Loss: 0.3490, Val AUC: 0.9999\n",
      "Epoch: 230, Loss: 0.3521, Val AUC: 0.9999\n",
      "Epoch: 240, Loss: 0.3519, Val AUC: 0.9999\n",
      "Epoch: 250, Loss: 0.3498, Val AUC: 0.9999\n",
      "Epoch: 260, Loss: 0.3491, Val AUC: 0.9998\n",
      "Epoch: 270, Loss: 0.3507, Val AUC: 0.9999\n",
      "Epoch: 280, Loss: 0.3497, Val AUC: 0.9999\n",
      "Epoch: 290, Loss: 0.3480, Val AUC: 0.9999\n",
      "Epoch: 300, Loss: 0.3491, Val AUC: 0.9999\n",
      "Epoch: 310, Loss: 0.3521, Val AUC: 0.9999\n",
      "Epoch: 320, Loss: 0.3477, Val AUC: 0.9999\n",
      "Epoch: 330, Loss: 0.3500, Val AUC: 0.9999\n",
      "Epoch: 340, Loss: 0.3478, Val AUC: 0.9999\n",
      "Epoch: 350, Loss: 0.3496, Val AUC: 0.9999\n",
      "Epoch: 360, Loss: 0.3510, Val AUC: 0.9999\n",
      "Epoch: 370, Loss: 0.3499, Val AUC: 0.9999\n",
      "Epoch: 380, Loss: 0.3479, Val AUC: 0.9999\n",
      "Epoch: 390, Loss: 0.3471, Val AUC: 0.9999\n",
      "Epoch: 400, Loss: 0.3491, Val AUC: 0.9999\n",
      "Epoch: 410, Loss: 0.3498, Val AUC: 0.9999\n",
      "Epoch: 420, Loss: 0.3481, Val AUC: 0.9999\n",
      "Epoch: 430, Loss: 0.3492, Val AUC: 0.9999\n",
      "Epoch: 440, Loss: 0.3484, Val AUC: 0.9999\n",
      "Epoch: 450, Loss: 0.3494, Val AUC: 0.9999\n",
      "Epoch: 460, Loss: 0.3492, Val AUC: 0.9999\n",
      "Epoch: 470, Loss: 0.3481, Val AUC: 0.9998\n",
      "Epoch: 480, Loss: 0.3497, Val AUC: 0.9999\n",
      "Epoch: 490, Loss: 0.3503, Val AUC: 0.9999\n",
      "Epoch: 500, Loss: 0.3489, Val AUC: 0.9999\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class GAEModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.2):\n",
    "        super(GAEModel, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        \n",
    "    def encode(self, x, edge_index, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight=edge_weight)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, z, edge_index):\n",
    "        src, dest = edge_index\n",
    "        return (z[src] * z[dest]).sum(dim=1)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        z = self.encode(data.x, data.edge_index, data.edge_attr)\n",
    "        return z\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GAEModel(in_channels=384, hidden_channels=128, out_channels=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Перенос данных на устройство\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Кодирование с использованием всех тренировочных ребер\n",
    "    z = model.encode(train_data.x, train_data.edge_index, train_data.edge_attr)\n",
    "    \n",
    "    # Предсказание на положительных ребрах\n",
    "    pos_edge_index = train_data.pos_edge_label_index\n",
    "    pos_pred = model.decode(z, pos_edge_index)\n",
    "    pos_label = torch.ones(pos_pred.size(0), device=device)\n",
    "    \n",
    "    if torch.isnan(pos_pred).any():\n",
    "        print(\"NaN detected in pos_pred\")\n",
    "    # Генерация отрицательных ребер с помощью negative_sampling\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index,\n",
    "        num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=pos_edge_index.size(1),\n",
    "        method='sparse'\n",
    "    )\n",
    "    neg_pred = model.decode(z, neg_edge_index)\n",
    "    neg_label = torch.zeros(neg_pred.size(0), device=device)\n",
    "    \n",
    "    # Объединение предсказаний и меток\n",
    "    pred = torch.cat([pos_pred, neg_pred], dim=0)\n",
    "    label = torch.cat([pos_label, neg_label], dim=0)\n",
    "    \n",
    "    # Вычисление потерь\n",
    "    loss = criterion(pred, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test(data_split):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Кодирование с использованием всех тренировочных ребер\n",
    "        z = model.encode(data_split.x, data_split.edge_index, data_split.edge_attr)\n",
    "        \n",
    "        # Предсказание на положительных ребрах\n",
    "        pos_edge_index = data_split.pos_edge_label_index\n",
    "        pos_pred = model.decode(z, pos_edge_index)\n",
    "        \n",
    "        # Предсказание на отрицательных ребрах\n",
    "        neg_edge_index = data_split.neg_edge_label_index\n",
    "        neg_pred = model.decode(z, neg_edge_index)\n",
    "        \n",
    "        # Объединение предсказаний и меток\n",
    "        preds = torch.cat([pos_pred, neg_pred], dim=0).cpu().numpy()\n",
    "        labels = torch.cat([\n",
    "            torch.ones(pos_pred.size(0), device=device),\n",
    "            torch.zeros(neg_pred.size(0), device=device)\n",
    "        ], dim=0).cpu().numpy()\n",
    "        \n",
    "        # Вычисление AUC\n",
    "        auc = roc_auc_score(labels, preds)\n",
    "        return auc\n",
    "\n",
    "# Обучение модели\n",
    "epochs = 500\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        val_auc = test(val_data)\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f}, Val AUC: {val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ae8e2-6fd4-4de2-bd85-be412f23dbdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
